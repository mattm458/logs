# Log 7-14-22

### Summary

This week was mostly development work, with a few small experiments and changes to the entrainment model. I found a bug that inflated the validation loss metrics, so the model with word embeddings does not perform as well as I thought. However, it still substantially outperforms previous iterations. The model is now incorporated into the dialogue engine.

### Model changes

Nothing particularly interesting happened with the dialogue model. I have been trying a few variations when I have extra time with different learning rates (a higher learning rate works just as well and trains much faster), teacher forcing schedules, and a few other things.

I did discover a bug in the model code where ground truth labels were being fed into the input during validation (i.e., teacher forcing was still active in validation), so the loss values in the chart were slightly inflated. However, fixing the issue in combination with some of the small experiments I described above resulted in almost getting back to where I was, so I think everything is OK again. 

| Performance | Training | Training loss | Evaluation | Evaluation loss | Teacher Forcing | L1 Loss    | Checkpoint | Extra Data                                                                                                                              |
|-------------|----------|---------------|------------|-----------------|-----------------|------------|------------|------------------------------------------------------------------------------------------------------------------------------------|
| Low        | Us       | Us            | Us         | Us              | Us              | 0.3815 | 229        |                                                                                            None                                        |                                                    |
| Medium        | Us       | Us            | Us         | Us              | Us              | 0.3663 | 306        |                                                                                 Word embeddings (old)                                                   |                                                    |
|         | Us       | Us            | Us         | Us              | Us              | ~~0.3121~~ | 310     |                                                                                 Word embeddings  (V2, buggy)                                                  |                                                    |
| High        | Us       | Us            | Us         | Us              | Us              | **0.3144** | 327     |                                                                                 Word embeddings  (V3)                                                  |                                                    |

I am in the process of researching exporting the platform-independent model artifact formats supported by PyTorch (TorchScript specifically) for both the entrainment model and Tacotron for easier integration with the dialogue engine.

### Dialogue Engine with Neural Entrainment

The neural entrainment model is now mostly integrated with the dialogue engine.

You can now interact with the dialogue engine and it will entrain to you, to whatever extent is permitted by the model. You can try this command to play with it:

```
python main.py \
	--audio-in sr \
	--sr-audio-in-device-index <device index> \
	--asr sphinx \
	--tts pyttsx3 \
	--entrainment-strategy neural \
	--neural-entrainment-ckpt neural-entrainment.ckpt \
	--feature-extractor praat rate \
	--dummy-extractor-config sample_config/dummy_feature_example.json \
	--dummy-extractor-fuzz 0.2 \
	--transformers pitch_range normalize_user \
	--tts tacotron2 \
	--tacotron2-ckpt tacotron-features-all-v2-22040.ckpt \
	--tacotron2-device-index <device index>
```

This will listen to you, record your speech, transcribe it with ASR, extract features, normalize them, produce response text, feed everything into the entrainment model, then produce output using Tacotron.

I made a separate branch for this code. It is available [here](https://github.com/mattm458/dialogue/tree/neural-entrainment). The command above requires a [Tacotron checkpoint](https://drive.google.com/file/d/1VBosH6jTf0JOSq9_ZXRpTsZVUam1SSGl/view?usp=sharing) and a [neural entrainment checkpoint](https://drive.google.com/file/d/1M2tzu6z8UpIabNdQOz5LsGI-VOsWifBH/view?usp=sharing).

I tried it a few times and while the Tacotron model still makes some mistakes, it is definitely reacting to me somewhat, although it's hard to tell if it's actually realistic or if I just want to hear a realistic conversation, so I do.

Doing this integration exercise has made me realize two things:

First, there are still some issues with the neural entrainment training loop, specifically around normalizing features from the speaker designated the human in the conversation. It doesn't reflect the difficulties in normalizing in real-time in the dialogue engine. It is definitely better to train the model how it will be used, and I've tried a couple of different normalization strategies in the dialogue engine that I never used to train the model. I will revisit this.

Second, the dialogue engine as written is at a dead end and I think it would be better to write it off as a first version or proof of concept and try a second version. We discussed this before, but actually doing this in real-world experimentation will require a different UI and client/server interaction like the BMIC collection code, so that's a major issue. But other issues include the fact that I had to do some pretty heavy restructuring around the entrainment engine in ways I hadn't considered before, and that we'll need to offload the computationally expensive operations to another machine in an experimental setting. So there will be a significant amount of refactoring anyway.



### What's next

Aside from more experimentation with the neural entrainment training loop, I am going to focus on the dialogue engine.